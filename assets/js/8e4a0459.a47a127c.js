"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[229],{2773:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>D,contentTitle:()=>N,default:()=>E,frontMatter:()=>F,metadata:()=>T,toc:()=>L});var r=n(4848),t=n(8453),o=n(6540),s=n(4164),c=n(3104),l=n(6347),i=n(205),u=n(7485),d=n(1682),g=n(679);function m(e){return o.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:a}=e;return!!a&&"object"==typeof a&&"value"in a}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:a,children:n}=e;return(0,o.useMemo)((()=>{const e=a??function(e){return m(e).map((e=>{let{props:{value:a,label:n,attributes:r,default:t}}=e;return{value:a,label:n,attributes:r,default:t}}))}(n);return function(e){const a=(0,d.X)(e,((e,a)=>e.value===a.value));if(a.length>0)throw new Error(`Docusaurus error: Duplicate values "${a.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[a,n])}function h(e){let{value:a,tabValues:n}=e;return n.some((e=>e.value===a))}function f(e){let{queryString:a=!1,groupId:n}=e;const r=(0,l.W6)(),t=function(e){let{queryString:a=!1,groupId:n}=e;if("string"==typeof a)return a;if(!1===a)return null;if(!0===a&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:a,groupId:n});return[(0,u.aZ)(t),(0,o.useCallback)((e=>{if(!t)return;const a=new URLSearchParams(r.location.search);a.set(t,e),r.replace({...r.location,search:a.toString()})}),[t,r])]}function b(e){const{defaultValue:a,queryString:n=!1,groupId:r}=e,t=p(e),[s,c]=(0,o.useState)((()=>function(e){let{defaultValue:a,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(a){if(!h({value:a,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${a}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return a}const r=n.find((e=>e.default))??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:a,tabValues:t}))),[l,u]=f({queryString:n,groupId:r}),[d,m]=function(e){let{groupId:a}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(a),[r,t]=(0,g.Dv)(n);return[r,(0,o.useCallback)((e=>{n&&t.set(e)}),[n,t])]}({groupId:r}),b=(()=>{const e=l??d;return h({value:e,tabValues:t})?e:null})();(0,i.A)((()=>{b&&c(b)}),[b]);return{selectedValue:s,selectValue:(0,o.useCallback)((e=>{if(!h({value:e,tabValues:t}))throw new Error(`Can't select invalid tab value=${e}`);c(e),u(e),m(e)}),[u,m,t]),tabValues:t}}var w=n(2303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function y(e){let{className:a,block:n,selectedValue:t,selectValue:o,tabValues:l}=e;const i=[],{blockElementScrollPositionUntilNextRender:u}=(0,c.a_)(),d=e=>{const a=e.currentTarget,n=i.indexOf(a),r=l[n].value;r!==t&&(u(a),o(r))},g=e=>{let a=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=i.indexOf(e.currentTarget)+1;a=i[n]??i[0];break}case"ArrowLeft":{const n=i.indexOf(e.currentTarget)-1;a=i[n]??i[i.length-1];break}}a?.focus()};return(0,r.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},a),children:l.map((e=>{let{value:a,label:n,attributes:o}=e;return(0,r.jsx)("li",{role:"tab",tabIndex:t===a?0:-1,"aria-selected":t===a,ref:e=>i.push(e),onKeyDown:g,onClick:d,...o,className:(0,s.A)("tabs__item",x.tabItem,o?.className,{"tabs__item--active":t===a}),children:n??a},a)}))})}function v(e){let{lazy:a,children:n,selectedValue:t}=e;const s=(Array.isArray(n)?n:[n]).filter(Boolean);if(a){const e=s.find((e=>e.props.value===t));return e?(0,o.cloneElement)(e,{className:"margin-top--md"}):null}return(0,r.jsx)("div",{className:"margin-top--md",children:s.map(((e,a)=>(0,o.cloneElement)(e,{key:a,hidden:e.props.value!==t})))})}function S(e){const a=b(e);return(0,r.jsxs)("div",{className:(0,s.A)("tabs-container",x.tabList),children:[(0,r.jsx)(y,{...a,...e}),(0,r.jsx)(v,{...a,...e})]})}function M(e){const a=(0,w.A)();return(0,r.jsx)(S,{...e,children:m(e.children)},String(a))}const j={tabItem:"tabItem_Ymn6"};function A(e){let{children:a,hidden:n,className:t}=e;return(0,r.jsx)("div",{role:"tabpanel",className:(0,s.A)(j.tabItem,t),hidden:n,children:a})}var k=n(1432);const F={sidebar_position:2,title:"Scraper API documentation"},N=void 0,T={id:"scraper-api-documentation",title:"Scraper API documentation",description:"Welcome to the API documentation for Manga-collector. Below you'll find detailed information on the available methods, including descriptions and usage examples.",source:"@site/docs/scraper-api-documentation.mdx",sourceDirName:".",slug:"/scraper-api-documentation",permalink:"/manga-collector/docs/scraper-api-documentation",draft:!1,unlisted:!1,editUrl:"https://github.com/AkioSarkiz/manga-collector/tree/main/docs/docs/scraper-api-documentation.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Scraper API documentation"},sidebar:"tutorialSidebar",previous:{title:"Intro",permalink:"/manga-collector/docs/intro"},next:{title:"External Sources",permalink:"/manga-collector/docs/external-sources"}},D={},L=[{value:"<code>getDetailedManga(url: string)</code>",id:"getdetailedmangaurl-string",level:3},{value:"Usage Example",id:"usage-example",level:4},{value:"<code>getDetailedChapter(url: string)</code>",id:"getdetailedchapterurl-string",level:3},{value:"Usage Example",id:"usage-example-1",level:4},{value:"<code>getLatestUpdates(page?: number)</code>",id:"getlatestupdatespage-number",level:3},{value:"Usage Example",id:"usage-example-2",level:4},{value:"<code>search(query: string)</code>",id:"searchquery-string",level:3},{value:"Usage Example",id:"usage-example-3",level:4}];function I(e){const a={code:"code",h3:"h3",h4:"h4",p:"p",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.p,{children:"Welcome to the API documentation for Manga-collector. Below you'll find detailed information on the available methods, including descriptions and usage examples."}),"\n",(0,r.jsx)(a.h3,{id:"getdetailedmangaurl-string",children:(0,r.jsx)(a.code,{children:"getDetailedManga(url: string)"})}),"\n",(0,r.jsx)(a.p,{children:"Fetches detailed information about a specific manga."}),"\n",(0,r.jsx)(a.h4,{id:"usage-example",children:"Usage Example"}),"\n",(0,r.jsxs)(M,{children:[(0,r.jsx)(A,{value:"manganato",label:"Manganato",default:!0,children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  const url = "https://manganato.com/manga-vz956108";\n\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGANATO);\n\n  // Second we scrape data from the website\n  const result = await scraper.getDetailedManga(url);\n\n  // Then we can see the result of scraping\n  console.log(result);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"mangadex",label:"Mangadex",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  const url = "https://mangadex.org/title/6b958848-c885-4735-9201-12ee77abcb3c/spy-family";\n\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGADEX);\n\n  // Second we scrape data from the website\n  const result = await scraper.getDetailedManga(url);\n\n  // Then we can see the result of scraping\n  console.log(result);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"toonily",label:"Toonily",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  const url = "https://toonily.com/webtoon/eleceed/";\n\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.TOONILY);\n\n  // Second we scrape data from the website\n  const result = await scraper.getDetailedManga(url);\n\n  // Then we can see the result of scraping\n  console.log(result);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})})]}),"\n",(0,r.jsx)(a.h3,{id:"getdetailedchapterurl-string",children:(0,r.jsx)(a.code,{children:"getDetailedChapter(url: string)"})}),"\n",(0,r.jsx)(a.p,{children:"Fetches detailed information about a specific chapter of a manga."}),"\n",(0,r.jsx)(a.h4,{id:"usage-example-1",children:"Usage Example"}),"\n",(0,r.jsxs)(M,{children:[(0,r.jsx)(A,{value:"manganato",label:"Manganato",default:!0,children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  const url = "https://manganato.com/manga-vz956108";\n\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGANATO);\n\n  // Second we scrape data from the website\n  const result = await scraper.getDetailedChapter(url);\n\n  // Then we can see the result of scraping\n  console.log(result);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"mangadex",label:"Mangadex",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  const url = "https://mangadex.org/chapter/0f7f932b-c426-46c6-9d36-2923ae3f7e13";\n\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGADEX);\n\n  // Second we scrape data from the website\n  const result = await scraper.getDetailedChapter(url);\n\n  // Then we can see the result of scraping\n  console.log(result);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"toonily",label:"Toonily",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  const url = "https://toonily.com/webtoon/not-a-lady-anymore/chapter-1/";\n\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.TOONILY);\n\n  // Second we scrape data from the website\n  const result = await scraper.getDetailedChapter(url);\n\n  // Then we can see the result of scraping\n  console.log(result);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})})]}),"\n",(0,r.jsx)(a.h3,{id:"getlatestupdatespage-number",children:(0,r.jsx)(a.code,{children:"getLatestUpdates(page?: number)"})}),"\n",(0,r.jsx)(a.p,{children:"Fetches the latest updates of mangas from various sources."}),"\n",(0,r.jsx)(a.h4,{id:"usage-example-2",children:"Usage Example"}),"\n",(0,r.jsxs)(M,{children:[(0,r.jsx)(A,{value:"manganato",label:"Manganato",default:!0,children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGANATO);\n\n  // Second we scrape data from the website\n  const firstPage = await scraper.getLatestUpdates();\n  const secondPage = await scraper.getLatestUpdates(2);\n\n  // Then we can see the result of scraping\n  console.log(firstPage);\n  console.log(secondPage);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"mangadex",label:"Mangadex",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGADEX);\n\n  // Second we scrape data from the website\n  const firstPage = await scraper.getLatestUpdates();\n  const secondPage = await scraper.getLatestUpdates(2);\n\n  // Then we can see the result of scraping\n  console.log(firstPage);\n  console.log(secondPage);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"toonily",label:"Toonily",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.TOONILY);\n\n  // Second we scrape data from the website\n  const firstPage = await scraper.getLatestUpdates();\n  const secondPage = await scraper.getLatestUpdates(2);\n\n  // Then we can see the result of scraping\n  console.log(firstPage);\n  console.log(secondPage);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})})]}),"\n",(0,r.jsx)(a.h3,{id:"searchquery-string",children:(0,r.jsx)(a.code,{children:"search(query: string)"})}),"\n",(0,r.jsx)(a.p,{children:"Finds mangas based on a search query."}),"\n",(0,r.jsx)(a.h4,{id:"usage-example-3",children:"Usage Example"}),"\n",(0,r.jsxs)(M,{children:[(0,r.jsx)(A,{value:"manganato",label:"Manganato",default:!0,children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGANATO);\n\n  // Second we scrape data from the website\n  const list = await scraper.search("san");\n\n  // Then we can see the result of scraping\n  console.log(list);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"mangadex",label:"Mangadex",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.MANGADEX);\n\n  // Second we scrape data from the website\n  const list = await scraper.search("san");\n\n  // Then we can see the result of scraping\n  console.log(list);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})}),(0,r.jsx)(A,{value:"toonily",label:"Toonily",children:(0,r.jsx)(k.A,{language:"js",showLineNumbers:!0,children:'import { MangaScraperFactory, MangaSource } from "manga-collector";\n\nconst main = async () => {\n  // First we need make a scraper via factory\n  const scraper = await MangaScraperFactory.make(MangaSource.TOONILY);\n\n  // Second we scrape data from the website\n  const list = await scraper.search("san");\n\n  // Then we can see the result of scraping\n  console.log(list);\n};\n\nmain()\n  .then(() => console.log("Done"))\n  .catch(console.error);\n'})})]})]})}function E(e={}){const{wrapper:a}={...(0,t.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(I,{...e})}):I(e)}}}]);